{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare Parser classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HtmlParser():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, element_parser_list):\n",
    "        # \n",
    "        self.element_parser_list = element_parser_list\n",
    "        \n",
    "    def parse(self, filename):\n",
    "        \n",
    "        with open(filename) as f:\n",
    "            content = BeautifulSoup(f, \"html.parser\")\n",
    "            \n",
    "        jobObject = {}\n",
    "        \n",
    "        for key, parser in self.element_parser_list.items():\n",
    "            jobObject[key] = parser(content)\n",
    "            \n",
    "            \n",
    "        return jobObject\n",
    "    \n",
    "    \n",
    "    def parse_pages(self, path_folder):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path_folder: path of folder that contains HTML files\n",
    "        Returns:\n",
    "            list of dict\n",
    "        \"\"\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define saving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jobs(jobs, filename, encoding='utf8'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        jobs: list of dict\n",
    "        filename: file name of saved file\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filename, 'w', encoding=encoding) as f:\n",
    "        json.dump(jobs, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function\n",
    "Parse HTML pages inside folder './html_pages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company': 'R2.ai招聘',\n",
       " 'title': '数据挖掘工程师',\n",
       " 'salary': '15k-30k ',\n",
       " 'requirement_keyword': '\\n15k-30k \\n/上海 /\\n经验1-3年 /\\n硕士及以上 /\\n全职\\n',\n",
       " 'keywords': '\\n其他\\n数据挖掘\\n算法\\n',\n",
       " 'categories': 'AI,机器学习',\n",
       " 'requirement': '\\n1.负责构建体系框架，公开数据等进行分析，挖掘特征；\\n2.负责大数据产品的规划，需求分析和产品设计和定义；\\n3.基于现有真实用户行为数据，能够从数据中发现能源的需求和业务场景；\\n4.参与业务部门临时数据分析需求的调研、分析及实现；\\n5.监测分析产品运营状况，持续优化产品功能改造和业务拓展方向，提出和落实产品优化改造方案。\\n6.撰写专题大数据分析报告。\\n职位要求：\\n1、统计学，数学，计算机等专业硕士及以上学历，2年以上数据分析工作经验\\n2、扎实的数理统计理论知识，如描述性统计，推断性统计，多元统计分析等\\n3、熟悉数据挖掘理论与方法，如聚类分析，决策树，逻辑回归，关联规则等\\n4、熟悉SQL语言进行数据处理和汇总统计分析\\n5、精通Excel，主要包括数据透视表，函数，图表和VBA等\\n6、熟练使用SPSS，SAS，R，Python中的任一工具进行数据分析工作\\n7、逻辑思维能力强，表达条理清晰，善于用PPT写作\\n',\n",
       " 'address': ' \\n上海 -\\n                    杨浦区\\n                                            - 政立路497号国正中心1号楼1508室\\n                                                            \\n'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_folder = './html_pages/'\n",
    "filename = './lagou.json'\n",
    "\n",
    "\n",
    "def parse_address(content):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        content (bs4.BeautifulSoup): class of bs4.BeautifulSoup\n",
    "        \n",
    "    Returns:\n",
    "        string: address\n",
    "    \"\"\"\n",
    "    \n",
    "    address = ' '\n",
    "\n",
    "    for tag in content.find('div', attrs={'class': 'work_addr'}).contents:\n",
    "#         print(type(tag))\n",
    "        text = ''\n",
    "\n",
    "        if type(tag) == bs4.element.Tag:\n",
    "            if tag.text == '查看地图':\n",
    "                continue\n",
    "            text = tag.text\n",
    "        else:\n",
    "            text = tag\n",
    "\n",
    "        address += text\n",
    "        \n",
    "    return address\n",
    "\n",
    "\n",
    "element_parsers = {'company': lambda content: content.find('div', attrs={'class': 'company'}).text,\n",
    "                   'title': lambda content: content.find('span', attrs={'class': 'name'}).text,\n",
    "                   'salary': lambda content: content.find('span', attrs={'class': 'salary'}).text,\n",
    "                   'requirement_keyword': lambda content: content.find('dd', attrs={'class': 'job_request'}).findNext('p').text,\n",
    "                   'keywords': lambda content: content.find('ul', attrs={'class': 'position-label'}).text,\n",
    "                   'categories': lambda content: content.find('dd', attrs={'class': 'job-advantage'}).findNext('p').contents[0],\n",
    "                   'requirement': lambda content: content.find('div', attrs={'class': 'job-detail'}).text,\n",
    "                   'address': lambda content: parse_address(content),\n",
    "\n",
    "                   }\n",
    "\n",
    "job = HtmlParser(element_parsers).parse('./html_pages/【数据挖掘工程师招聘】_R2.ai招聘-拉勾网.html')\n",
    "job\n",
    "# jobs = HtmlParser(element_parsers).parse_pages(path_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_jobs(jobs, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
