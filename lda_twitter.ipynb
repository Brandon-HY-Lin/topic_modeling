{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'abcnews-date-text.csv'\n",
    "filename = 'twitter_trump_2019_05.csv'\n",
    "raw_docs = pd.read_csv(filename, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robert Mueller came to the Oval Office (along ...</td>\n",
       "      <td>05-30-2019 15:34:11</td>\n",
       "      <td>1134120831389392896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“Comey and Brennan are turning on each other.”...</td>\n",
       "      <td>05-30-2019 14:41:24</td>\n",
       "      <td>1134107544681455616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Congressman John Ratcliffe “The Trump Campaign...</td>\n",
       "      <td>05-30-2019 13:41:43</td>\n",
       "      <td>1134092525218590721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russia Russia Russia! That’s all you heard at ...</td>\n",
       "      <td>05-30-2019 11:57:47</td>\n",
       "      <td>1134066371510378501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>....say he fought back against this phony crim...</td>\n",
       "      <td>05-30-2019 11:57:47</td>\n",
       "      <td>1134066372584062976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           created_at  \\\n",
       "0  Robert Mueller came to the Oval Office (along ...  05-30-2019 15:34:11   \n",
       "1  “Comey and Brennan are turning on each other.”...  05-30-2019 14:41:24   \n",
       "2  Congressman John Ratcliffe “The Trump Campaign...  05-30-2019 13:41:43   \n",
       "3  Russia Russia Russia! That’s all you heard at ...  05-30-2019 11:57:47   \n",
       "4  ....say he fought back against this phony crim...  05-30-2019 11:57:47   \n",
       "\n",
       "                id_str  \n",
       "0  1134120831389392896  \n",
       "1  1134107544681455616  \n",
       "2  1134092525218590721  \n",
       "3  1134066371510378501  \n",
       "4  1134066372584062976  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Robert Mueller came to the Oval Office (along ...\n",
       "1    “Comey and Brennan are turning on each other.”...\n",
       "2    Congressman John Ratcliffe “The Trump Campaign...\n",
       "3    Russia Russia Russia! That’s all you heard at ...\n",
       "4    ....say he fought back against this phony crim...\n",
       "5    Russia Russia Russia! That’s all you heard at ...\n",
       "6    ....say he fought back against this phony crim...\n",
       "7    The Greatest Presidential Harassment in histor...\n",
       "8    I was not informed about anything having to do...\n",
       "9    Great show tonight @seanhannity you really get...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_docs['text'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "def preprocess_docs(raw_docs, num_docs=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        raw_docs: pandas.DataFrame\n",
    "\n",
    "    Returns:\n",
    "        list(list): return list of list\n",
    "    \"\"\"\n",
    "    if num_docs is None:\n",
    "        num_docs = 10\n",
    "        \n",
    "    docs = list()\n",
    "\n",
    "    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    for d in raw_docs['text'][:num_docs]:\n",
    "        \n",
    "#         print(d)\n",
    "        processed_tokens = list()\n",
    "        # normalize and tokenize\n",
    "        tokens = gensim.utils.simple_preprocess(d)\n",
    "    \n",
    "#         print(tokens)\n",
    "#         pdb.set_trace()\n",
    "\n",
    "        # lemmatize then stem\n",
    "        for t in tokens:\n",
    "            # remove stop words\n",
    "            if t not in gensim.parsing.preprocessing.STOPWORDS:\n",
    "    #             print(t)\n",
    "                p_t = stemmer.stem(lemmatizer.lemmatize(t, pos='v'))\n",
    "                processed_tokens.append(p_t)\n",
    "            \n",
    "    #             pdb.set_trace()\n",
    "\n",
    "        docs.append(processed_tokens)\n",
    "    \n",
    "    return docs\n",
    "\n",
    "\n",
    "docs = preprocess_docs(raw_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[['robert', 'mueller', 'come', 'oval', 'offic', 'potenti', 'candid', 'seek', 'name', 'director', 'fbi', 'posit', 'year', 'tell', 'day', 'name', 'special', 'counsel', 'total', 'conflict', 'nice'], ['comey', 'brennan', 'turn', 'kilmead'], ['congressman', 'john', 'ratcliff', 'trump', 'campaign', 'clear', 'conspir', 'collud', 'foxnew'], ['russia', 'russia', 'russia', 'hear', 'begin', 'witch', 'hunt', 'hoax', 'russia', 'disappear', 'russia', 'help', 'elect', 'crime', 'exist', 'dem', 'partner', 'fake', 'news', 'media'], ['fight', 'phoni', 'crime', 'exist', 'horrend', 'fals', 'accus', 'shouldn', 'fight', 'sit', 'obstruct', 'mueller', 'obstruct', 'presidenti', 'harass'], ['russia', 'russia', 'russia', 'hear', 'begin', 'witch', 'hunt', 'hoax', 'russia', 'disappear', 'russia', 'help', 'elect', 'crime', 'exist', 'dem', 'partner', 'fake', 'news', 'media'], ['fight', 'phoni', 'crime', 'exist', 'horrend', 'fals', 'acquisit', 'shouldn', 'fight', 'sit', 'obstruct', 'mueller', 'obstruct', 'presidenti', 'harass'], ['greatest', 'presidenti', 'harass', 'histori', 'spend', 'dark', 'year', 'unlimit', 'access', 'peopl', 'resourc', 'cooper', 'high', 'conflict', 'robert', 'mueller', 'bring', 'charg', 'charg', 'bring'], ['inform', 'have', 'navi', 'ship', 'uss', 'john', 'mccain', 'recent', 'visit', 'japan', 'flotus', 'love', 'great', 'militari', 'men', 'women', 'spectacular', 'job'], ['great', 'tonight', 'seanhann', 'foxnew', 'number', 'far', 'tell', 'mark', 'levin', 'congrat', 'have', 'number', 'book']]\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(docs):\n",
    "    return gensim.corpora.Dictionary(docs)\n",
    "\n",
    "dictionary = create_dictionary(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bows = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 2),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 1),\n",
       " (12, 1),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 1)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_bow = gensim.models.LdaModel(bows,\n",
    "                                        num_topics=3,\n",
    "                                        id2word=dictionary,\n",
    "                                        passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0: topic= 0.033*\"name\" + 0.022*\"robert\" + 0.022*\"john\" + 0.021*\"year\" + 0.021*\"congressman\" + 0.021*\"conspir\" + 0.021*\"campaign\" + 0.021*\"trump\" + 0.021*\"foxnew\" + 0.021*\"ratcliff\"\n",
      "index 1: topic= 0.029*\"number\" + 0.028*\"have\" + 0.028*\"great\" + 0.025*\"bring\" + 0.024*\"charg\" + 0.018*\"tell\" + 0.017*\"conflict\" + 0.017*\"foxnew\" + 0.017*\"congrat\" + 0.017*\"tonight\"\n",
      "index 2: topic= 0.096*\"russia\" + 0.040*\"obstruct\" + 0.040*\"exist\" + 0.040*\"crime\" + 0.040*\"fight\" + 0.022*\"harass\" + 0.022*\"presidenti\" + 0.022*\"mueller\" + 0.022*\"disappear\" + 0.022*\"elect\"\n"
     ]
    }
   ],
   "source": [
    "for index, topic in lda_model_bow.print_topics(-1):\n",
    "    print('index {}: topic= {}'.format(index, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bows2tfidf(bows):\n",
    "    tfidf = gensim.models.TfidfModel(bows)\n",
    "    corpus_tfidf = tfidf[bows]\n",
    "    \n",
    "    return corpus_tfidf\n",
    "\n",
    "corpus_tfidf = bows2tfidf(bows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.interfaces.TransformedCorpus"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaModel(corpus_tfidf,\n",
    "                                   num_topics=3,\n",
    "                                   id2word=dictionary,\n",
    "                                   passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: topic= 0.015*\"ship\" + 0.015*\"job\" + 0.015*\"men\" + 0.015*\"recent\" + 0.015*\"love\" + 0.015*\"militari\" + 0.015*\"visit\" + 0.015*\"spectacular\" + 0.015*\"mccain\" + 0.015*\"flotus\"\n",
      "Index 1: topic= 0.030*\"fight\" + 0.030*\"obstruct\" + 0.019*\"fals\" + 0.019*\"horrend\" + 0.019*\"shouldn\" + 0.019*\"phoni\" + 0.019*\"sit\" + 0.017*\"name\" + 0.016*\"presidenti\" + 0.016*\"harass\"\n",
      "Index 2: topic= 0.038*\"russia\" + 0.017*\"number\" + 0.016*\"comey\" + 0.016*\"kilmead\" + 0.016*\"turn\" + 0.016*\"brennan\" + 0.015*\"bring\" + 0.015*\"charg\" + 0.015*\"foxnew\" + 0.013*\"collud\"\n"
     ]
    }
   ],
   "source": [
    "for index, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Index {}: topic= {}'.format(index, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
