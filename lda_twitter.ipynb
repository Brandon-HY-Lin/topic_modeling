{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'abcnews-date-text.csv'\n",
    "filename = 'twitter_trump_2019_05.csv'\n",
    "raw_docs = pd.read_csv(filename, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robert Mueller came to the Oval Office (along ...</td>\n",
       "      <td>05-30-2019 15:34:11</td>\n",
       "      <td>1134120831389392896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“Comey and Brennan are turning on each other.”...</td>\n",
       "      <td>05-30-2019 14:41:24</td>\n",
       "      <td>1134107544681455616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Congressman John Ratcliffe “The Trump Campaign...</td>\n",
       "      <td>05-30-2019 13:41:43</td>\n",
       "      <td>1134092525218590721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russia Russia Russia! That’s all you heard at ...</td>\n",
       "      <td>05-30-2019 11:57:47</td>\n",
       "      <td>1134066371510378501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>....say he fought back against this phony crim...</td>\n",
       "      <td>05-30-2019 11:57:47</td>\n",
       "      <td>1134066372584062976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           created_at  \\\n",
       "0  Robert Mueller came to the Oval Office (along ...  05-30-2019 15:34:11   \n",
       "1  “Comey and Brennan are turning on each other.”...  05-30-2019 14:41:24   \n",
       "2  Congressman John Ratcliffe “The Trump Campaign...  05-30-2019 13:41:43   \n",
       "3  Russia Russia Russia! That’s all you heard at ...  05-30-2019 11:57:47   \n",
       "4  ....say he fought back against this phony crim...  05-30-2019 11:57:47   \n",
       "\n",
       "                id_str  \n",
       "0  1134120831389392896  \n",
       "1  1134107544681455616  \n",
       "2  1134092525218590721  \n",
       "3  1134066371510378501  \n",
       "4  1134066372584062976  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Robert Mueller came to the Oval Office (along ...\n",
       "1    “Comey and Brennan are turning on each other.”...\n",
       "2    Congressman John Ratcliffe “The Trump Campaign...\n",
       "3    Russia Russia Russia! That’s all you heard at ...\n",
       "4    ....say he fought back against this phony crim...\n",
       "5    Russia Russia Russia! That’s all you heard at ...\n",
       "6    ....say he fought back against this phony crim...\n",
       "7    The Greatest Presidential Harassment in histor...\n",
       "8    I was not informed about anything having to do...\n",
       "9    Great show tonight @seanhannity you really get...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_docs['text'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "def preprocess_docs(raw_docs, num_docs=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        raw_docs: pandas.DataFrame\n",
    "\n",
    "    Returns:\n",
    "        list(list): return list of list\n",
    "    \"\"\"\n",
    "    if num_docs is None:\n",
    "        num_docs = 10\n",
    "        \n",
    "    docs = list()\n",
    "\n",
    "    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    for d in raw_docs['text'][:num_docs]:\n",
    "        \n",
    "#         print(d)\n",
    "        processed_tokens = list()\n",
    "        # normalize and tokenize\n",
    "        tokens = gensim.utils.simple_preprocess(d)\n",
    "    \n",
    "#         print(tokens)\n",
    "#         pdb.set_trace()\n",
    "\n",
    "        # lemmatize then stem\n",
    "        for t in tokens:\n",
    "            # remove stop words\n",
    "            if t not in gensim.parsing.preprocessing.STOPWORDS:\n",
    "    #             print(t)\n",
    "                p_t = stemmer.stem(lemmatizer.lemmatize(t, pos='v'))\n",
    "                processed_tokens.append(p_t)\n",
    "            \n",
    "    #             pdb.set_trace()\n",
    "\n",
    "        docs.append(processed_tokens)\n",
    "    \n",
    "    return docs\n",
    "\n",
    "\n",
    "docs = preprocess_docs(raw_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[['robert', 'mueller', 'come', 'oval', 'offic', 'potenti', 'candid', 'seek', 'name', 'director', 'fbi', 'posit', 'year', 'tell', 'day', 'name', 'special', 'counsel', 'total', 'conflict', 'nice'], ['comey', 'brennan', 'turn', 'kilmead'], ['congressman', 'john', 'ratcliff', 'trump', 'campaign', 'clear', 'conspir', 'collud', 'foxnew'], ['russia', 'russia', 'russia', 'hear', 'begin', 'witch', 'hunt', 'hoax', 'russia', 'disappear', 'russia', 'help', 'elect', 'crime', 'exist', 'dem', 'partner', 'fake', 'news', 'media'], ['fight', 'phoni', 'crime', 'exist', 'horrend', 'fals', 'accus', 'shouldn', 'fight', 'sit', 'obstruct', 'mueller', 'obstruct', 'presidenti', 'harass'], ['russia', 'russia', 'russia', 'hear', 'begin', 'witch', 'hunt', 'hoax', 'russia', 'disappear', 'russia', 'help', 'elect', 'crime', 'exist', 'dem', 'partner', 'fake', 'news', 'media'], ['fight', 'phoni', 'crime', 'exist', 'horrend', 'fals', 'acquisit', 'shouldn', 'fight', 'sit', 'obstruct', 'mueller', 'obstruct', 'presidenti', 'harass'], ['greatest', 'presidenti', 'harass', 'histori', 'spend', 'dark', 'year', 'unlimit', 'access', 'peopl', 'resourc', 'cooper', 'high', 'conflict', 'robert', 'mueller', 'bring', 'charg', 'charg', 'bring'], ['inform', 'have', 'navi', 'ship', 'uss', 'john', 'mccain', 'recent', 'visit', 'japan', 'flotus', 'love', 'great', 'militari', 'men', 'women', 'spectacular', 'job'], ['great', 'tonight', 'seanhann', 'foxnew', 'number', 'far', 'tell', 'mark', 'levin', 'congrat', 'have', 'number', 'book']]\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(docs):\n",
    "    return gensim.corpora.Dictionary(docs)\n",
    "\n",
    "dictionary = create_dictionary(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bows = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bows[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_bow = gensim.models.LdaModel(bows,\n",
    "                                        num_topics=3,\n",
    "                                        id2word=dictionary,\n",
    "                                        passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0: topic= 0.115*\"russia\" + 0.026*\"exist\" + 0.026*\"crime\" + 0.026*\"dem\" + 0.026*\"partner\" + 0.026*\"media\" + 0.026*\"hoax\" + 0.026*\"hunt\" + 0.026*\"begin\" + 0.026*\"help\"\n",
      "index 1: topic= 0.051*\"fight\" + 0.051*\"obstruct\" + 0.040*\"mueller\" + 0.039*\"harass\" + 0.039*\"presidenti\" + 0.027*\"crime\" + 0.027*\"exist\" + 0.027*\"phoni\" + 0.027*\"shouldn\" + 0.027*\"horrend\"\n",
      "index 2: topic= 0.030*\"john\" + 0.028*\"name\" + 0.017*\"foxnew\" + 0.017*\"have\" + 0.017*\"great\" + 0.017*\"inform\" + 0.017*\"militari\" + 0.017*\"japan\" + 0.017*\"men\" + 0.017*\"mccain\"\n"
     ]
    }
   ],
   "source": [
    "for index, topic in lda_model_bow.print_topics(-1):\n",
    "    print('index {}: topic= {}'.format(index, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "russia exist crime dem partner media hoax hunt begin help \n",
      "\n",
      "Topic 1:\n",
      "fight obstruct mueller harass presidenti crime exist phoni shouldn horrend \n",
      "\n",
      "Topic 2:\n",
      "john name foxnew have great inform militari japan men mccain \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, topic in lda_model_bow.show_topics(-1, formatted=False):\n",
    "    print('Topic {}:'.format(index))\n",
    "    \n",
    "    for word, weight in topic:\n",
    "        print('{} '.format(word), end='')\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bows2tfidf(bows):\n",
    "    tfidf = gensim.models.TfidfModel(bows)\n",
    "    corpus_tfidf = tfidf[bows]\n",
    "    \n",
    "    return corpus_tfidf\n",
    "\n",
    "corpus_tfidf = bows2tfidf(bows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.interfaces.TransformedCorpus"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaModel(corpus_tfidf,\n",
    "                                   num_topics=3,\n",
    "                                   id2word=dictionary,\n",
    "                                   passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: topic= 0.040*\"russia\" + 0.017*\"brennan\" + 0.017*\"turn\" + 0.017*\"kilmead\" + 0.017*\"comey\" + 0.015*\"john\" + 0.014*\"campaign\" + 0.014*\"clear\" + 0.014*\"conspir\" + 0.014*\"congressman\"\n",
      "Index 1: topic= 0.013*\"obstruct\" + 0.013*\"fight\" + 0.013*\"accus\" + 0.012*\"horrend\" + 0.012*\"fals\" + 0.012*\"phoni\" + 0.011*\"sit\" + 0.011*\"shouldn\" + 0.011*\"exist\" + 0.011*\"crime\"\n",
      "Index 2: topic= 0.024*\"fight\" + 0.024*\"obstruct\" + 0.017*\"number\" + 0.016*\"name\" + 0.016*\"charg\" + 0.016*\"bring\" + 0.016*\"harass\" + 0.016*\"presidenti\" + 0.015*\"shouldn\" + 0.015*\"sit\"\n"
     ]
    }
   ],
   "source": [
    "for index, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Index {}: topic= {}'.format(index, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "russia brennan turn kilmead comey john campaign clear conspir congressman \n",
      "\n",
      "Topic 1: \n",
      "obstruct fight accus horrend fals phoni sit shouldn exist crime \n",
      "\n",
      "Topic 2: \n",
      "fight obstruct number name charg bring harass presidenti shouldn sit \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, topic in lda_model_tfidf.show_topics(-1, formatted=False):\n",
    "    print('Topic {}: '.format(index))\n",
    "    \n",
    "    for word, weight in topic:\n",
    "        print('{} '.format(word), end='')\n",
    "#         print('{} '.format(word))\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
